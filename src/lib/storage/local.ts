import { StorageProvider, FileMeta } from './types';
import { db, FileChunk } from './db';
import { migrateFromIdbToDexie } from './migrate';
import { generateEmbedding, chunkText, cosineSimilarity } from '../ai/embeddings';

export class LocalStorageProvider implements StorageProvider {
    private syncEngine: any; // Type 'any' to avoid circular dependency with SyncEngine

    setSyncEngine(engine: any) {
        this.syncEngine = engine;
    }
    
    async init() {
        // Run migration logic once on init
        await migrateFromIdbToDexie();
    }

    async indexFile(path: string, content: string) {
        // Only index text-based files in knowledge base (misc/ or source files)
        const isKnowledge = path.startsWith('misc/') || path.endsWith('.source.md');
        if (!isKnowledge) return;

        try {
            console.log(`[RAG] Indexing ${path}...`);
            // 1. Clear old chunks for this file
            await db.chunks.where('filePath').equals(path).delete();

            // 2. Chunk text
            const chunks = chunkText(content);
            
            // 3. Generate embeddings and save
            for (const text of chunks) {
                const embedding = await generateEmbedding(text);
                await db.chunks.add({
                    filePath: path,
                    content: text,
                    embedding
                });
            }
            console.log(`[RAG] Finished indexing ${path} (${chunks.length} chunks).`);
        } catch (e) {
            console.error(`[RAG] Failed to index ${path}`, e);
        }
    }

    async listFiles(prefix: string): Promise<FileMeta[]> {
        // Dexie 'startsWith' query
        // "misc" -> "misc/"
        // BUT: our paths are 'misc/foo.txt'.
        // If prefix is '', get all.
        
        let collection;
        if (!prefix || prefix === 'root') {
             collection = db.files.toCollection();
        } else {
             // We want all files that START with "{prefix}/" OR equal "{prefix}" (if it's a file)
             // Actually, the File Explorer passes 'misc'.
             // We want 'misc/foo', 'misc/bar'.
             // We want 'misc/foo', 'misc/bar'.
             collection = db.files.where('path').startsWith(prefix);
        }

        const records = await collection.filter(f => !f.deleted).toArray();
        
        return records.map(r => ({
            id: r.path,
            name: r.path.split('/').pop() || r.path,
            path: r.path,
            updatedAt: r.updatedAt,
            type: r.type,
            remoteId: r.remoteId
        }));
    }

    async getFile(virtualPath: string): Promise<FileMeta | null> {
        const item = await db.files.get(virtualPath);
        if (!item || item.deleted) return null;
        
        return {
            id: item.path,
            name: item.path.split('/').pop() || item.path,
            path: item.path,
            type: item.type,
            updatedAt: item.updatedAt,
            remoteId: item.remoteId
        };
    }

    async readFile(virtualPath: string): Promise<string | Blob | ArrayBuffer | null> {
        const file = await db.files.get(virtualPath);
        if (!file || file.deleted) return null;
        return file.content;
    }

    async saveFile(virtualPath: string, content: string | Blob | ArrayBuffer, remoteId?: string): Promise<void> {
        await this.ensureParent(virtualPath);
        
        // Optimistic Update
        await db.transaction('rw', db.files, async () => {
            const existing = await db.files.get(virtualPath);
            await db.files.put({
                path: virtualPath,
                content: content,
                updatedAt: Date.now(),
                type: 'file',
                remoteId: remoteId || existing?.remoteId, // Preserve remoteId if updating content locally
                dirty: 1, // Mark as dirty (needs sync up)
                deleted: 0
            });
        });

        if (typeof content === 'string') {
            this.indexFile(virtualPath, content);
        }
    }

    async appendFile(virtualPath: string, content: string): Promise<void> {
        await this.ensureParent(virtualPath);

        let finalContent = "";
        await db.transaction('rw', db.files, async () => {
             const existing = await db.files.get(virtualPath);
             finalContent = (existing && typeof existing.content === 'string') 
                ? (existing.content + '\n\n' + content) 
                : content;
             
             await db.files.put({
                path: virtualPath,
                content: finalContent,
                updatedAt: Date.now(),
                type: 'file',
                remoteId: existing?.remoteId,
                dirty: 1,
                deleted: 0
            });
        });

        // Background Indexing
        this.indexFile(virtualPath, finalContent);
    }

    async updateFile(virtualPath: string, newContent: string): Promise<void> {
        // 1. Verify existence (Logic: Can only update what exists)
        const existing = await db.files.get(virtualPath);
        if (!existing || existing.deleted) {
            throw new Error(`File '${virtualPath}' not found. Cannot update.`);
        }

        // 2. Perform Update (Overwrite content)
        await db.transaction('rw', db.files, async () => {
             await db.files.update(virtualPath, {
                content: newContent,
                updatedAt: Date.now(),
                dirty: 1, // Mark dirty for sync
                deleted: 0
             });
        });

        // 3. Re-Index for RAG
        this.indexFile(virtualPath, newContent);
    }

    async getRecentLogs(limitHours: number): Promise<string> {
        const now = new Date();
        const startTime = new Date(now.getTime() - limitHours * 60 * 60 * 1000);
        
        // Get Dates for Today and Yesterday (using local time logic implicitly via Date)
        const todayDate = new Date();
        const yesterdayDate = new Date(now.getTime() - 24 * 60 * 60 * 1000);

        const todayStr = this.formatDate(todayDate);
        const yesterdayStr = this.formatDate(yesterdayDate);
        
        let logs = "";

        // 1. If window crosses midnight (start time is yesterday), read yesterday's log first
        if (startTime.getDate() !== now.getDate()) {
            const yesterdayContent = await this.readFile(`history/${yesterdayStr}.md`);
            if (typeof yesterdayContent === 'string') {
                logs += this.filterLogByTime(yesterdayContent, startTime, yesterdayDate) + "\n";
            }
        }

        // 2. Read Today's log
        const todayContent = await this.readFile(`history/${todayStr}.md`);
        if (typeof todayContent === 'string') {
            logs += this.filterLogByTime(todayContent, startTime, todayDate);
        }

        return logs || "No recent history.";
    }

    private formatDate(date: Date): string {
        return `${date.getFullYear()}-${String(date.getMonth() + 1).padStart(2, '0')}-${String(date.getDate()).padStart(2, '0')}`;
    }

    private filterLogByTime(content: string, startTime: Date, fileDate: Date): string {
        const blocks = content.split('###');
        let result = "";

        for (const block of blocks) {
            if (!block.trim()) continue;

            // Extract Time: " 10:30:05 PM\n**User**..."
            const timeMatch = block.match(/^\s*(\d{1,2}:\d{2}:\d{2}\s?(?:AM|PM)?)/i);
            if (timeMatch) {
                const timeStr = timeMatch[1];
                
                // Parse Time
                const entryDate = new Date(fileDate);
                const [time, modifier] = timeStr.trim().split(' ');
                let [hours, minutes, seconds] = time.split(':').map(Number);
                
                if (modifier) {
                    if (modifier.toUpperCase() === 'PM' && hours < 12) hours += 12;
                    if (modifier.toUpperCase() === 'AM' && hours === 12) hours = 0;
                }
                
                entryDate.setHours(hours, minutes, seconds);

                if (entryDate >= startTime) {
                    result += '###' + block; 
                }
            } else {
                // Include blocks without timestamp (e.g. continuations or system headers)
                // if they are part of the file we typically assume they are relevant if the file is relevant.
                // But for safety in a rolling window, maybe we skip if we can't date it?
                // Actually, 'Added Source' logs might be system logs with timestamps.
                // If it HAS NO timestamp, it might be garbage or noise. Let's keep it to be safe.
                result += '###' + block;
            }
        }
        return result;
    }

    async renameFile(oldPath: string, newPath: string): Promise<void> {
        await this.ensureParent(newPath);

        await db.transaction('rw', db.files, db.chunks, async () => {
            const existing = await db.files.get(oldPath);
            if (!existing) throw new Error(`File not found: ${oldPath}`);

            // 1. Rename the item itself
            await db.files.put({
                ...existing,
                path: newPath,
                updatedAt: Date.now(),
                dirty: 1,
                deleted: 0
            });
            await db.files.delete(oldPath);

            // 1b. Migrate Chunks for this file
            await db.chunks.where('filePath').equals(oldPath).modify({ filePath: newPath });

            // 2. If it's a folder, rename all children recursively
            if (existing.type === 'folder') {
                const prefix = oldPath + '/';
                const children = await db.files.where('path').startsWith(prefix).toArray();
                
                for (const child of children) {
                    const childNewPath = child.path.replace(prefix, newPath + '/');
                    
                    // Create new child record
                    await db.files.put({
                        ...child,
                        path: childNewPath,
                        updatedAt: Date.now(),
                        dirty: 1, // Mark dirty so sync engine moves them on remote
                        deleted: 0
                    });
                    
                    // Delete old child record
                    await db.files.delete(child.path);

                    // Migrate chunks for child
                    await db.chunks.where('filePath').equals(child.path).modify({ filePath: childNewPath });
                }
            }
        });
    }

    async deleteFile(virtualPath: string): Promise<void> {
        // Soft delete for sync
        await db.transaction('rw', db.files, db.chunks, async () => {
            const existing = await db.files.get(virtualPath);
            if (!existing) return;

            // 1. Delete the item itself
            await db.files.update(virtualPath, { deleted: 1, dirty: 1 });

            // 2. Delete semantic chunks
            await db.chunks.where('filePath').equals(virtualPath).delete();

            // 3. If it's a folder, soft-delete all children recursively
            if (existing.type === 'folder') {
                const prefix = virtualPath + '/';
                const children = await db.files.where('path').startsWith(prefix).toArray();
                
                for (const child of children) {
                    await db.files.update(child.path, { deleted: 1, dirty: 1 });
                    await db.chunks.where('filePath').equals(child.path).delete();
                }
            }
        });
    }

    async createFolder(virtualPath: string): Promise<void> {
        await this.ensureParent(virtualPath);
        
        await db.transaction('rw', db.files, async () => {
             const existing = await db.files.get(virtualPath);
             // Always update timestamp and dirty
             await db.files.put({
                 path: virtualPath,
                 content: '',
                 updatedAt: Date.now(),
                 type: 'folder',
                 remoteId: existing?.remoteId,
                 dirty: 1, // Crucial for sync
                 deleted: 0
             });
        });
    }

    private async ensureParent(path: string) {
        const parts = path.split('/');
        if (parts.length <= 1) return;

        // Try to find parent
        const parentPath = parts.slice(0, -1).join('/');
        
        // Optimize: check if exists first
        const parent = await db.files.get(parentPath);
        if (parent && !parent.deleted) return;

        // Check recursively (grandparent)
        await this.ensureParent(parentPath);

        // Create Parent Folder
        await db.files.put({
            path: parentPath,
            content: '',
            updatedAt: Date.now(),
            type: 'folder',
            dirty: 1,
            deleted: 0
        });
    }

    async resetSyncState() {
        console.log("Reseting sync state...");
        // 1. Clear Settings
        await db.settings.delete('drive_sync_token');
        await db.settings.delete('drive_root_id');
        await db.settings.delete('drive_root_id_writable');

        // 2. Clear Remote IDs & Mark Dirty
        await db.transaction('rw', db.files, async () => {
             const all = await db.files.toArray();
             for (const file of all) {
                 await db.files.update(file.path, { 
                     remoteId: undefined, 
                     dirty: 1 
                 });
             }
        });
        console.log("Sync state reset. All files marked dirty.");
    }

    async factoryReset() {
        console.warn("PERFORMING FACTORY RESET...");
        await db.transaction('rw', db.files, db.settings, db.chunks, async () => {
            await db.files.clear();
            await db.settings.clear();
            await db.chunks.clear();
        });
        
        // Re-init default folders
        await this.ensureFolder('misc');
        await this.ensureFolder('history');
        
        console.log("Factory Reset Complete.");
    }

    async forceSync() {
        console.log("Force Sync Requested");
        if (this.syncEngine) {
            await this.syncEngine.sync();
        }
    }

    private async ensureFolder(path: string) {
        await db.files.put({
            path,
            content: '',
            updatedAt: Date.now(),
            type: 'folder',
            dirty: 1,
            deleted: 0
        });
    }

    async getKnowledgeContext(query?: string): Promise<string> {
        if (query) {
            console.log(`[RAG] Performing Semantic Search for: "${query}"`);
            try {
                const queryEmbedding = await generateEmbedding(query);
                const allChunks = await db.chunks.toArray();
                
                if (allChunks.length === 0) {
                    return "--- Knowledge Base ---\nNo indexed memory found. Falling back to basic context.\n" + await this.getLegacyKnowledgeContext();
                }

                // Rank chunks by similarity
                const ranked = allChunks.map(chunk => ({
                    chunk,
                    similarity: cosineSimilarity(queryEmbedding, chunk.embedding)
                })).sort((a, b) => b.similarity - a.similarity);

                // FILENAME BOOSTING
                // If the user explicitly mentions a file (e.g. "Schema Theory"), we MUST include it regardless of vector score.
                const queryLower = query.toLowerCase();
                const boostedChunks: typeof ranked = [];
                const seenChunkIds = new Set<string>();

                // 1. Find matched files
                const allFiles = await db.files.toArray();
                const matchedFiles = allFiles.filter(f => {
                   if (!f.path.startsWith('misc/')) return false;
                   const filename = f.path.split('/').pop()?.toLowerCase() || "";
                   // Boosting Logic: If filename is found in query OR query is found in filename
                   // (ignoring very short queries)
                   if (queryLower.length > 3 && filename.includes(queryLower)) return true;
                   if (filename.length > 3 && queryLower.includes(filename)) return true;
                   return false;
                });

                if (matchedFiles.length > 0) {
                     console.log(`[RAG] Filename Match Found: ${matchedFiles.map(f => f.path).join(', ')}`);
                     // Get all chunks for these files
                     for (const file of matchedFiles) {
                         const fileChunks = allChunks.filter(c => c.filePath === file.path);
                         for (const c of fileChunks) {
                             if (!seenChunkIds.has(c.content)) { // simple content dedup
                                 boostedChunks.push({ chunk: c, similarity: 1.0 }); // Artificially high score
                                 seenChunkIds.add(c.content);
                             }
                         }
                     }
                }

                // 2. Select Top Chunks (Boosted + Semantic)
                const semanticChunks = ranked.filter(r => r.similarity > 0.1 && !seenChunkIds.has(r.chunk.content));
                
                // Combine: Boosted first, then highest semantic
                // Total Limit: 8 chunks (approx 2k tokens)
                const combined = [...boostedChunks, ...semanticChunks].slice(0, 8);
                
                if (combined.length === 0) {
                    return "--- Knowledge Base ---\nNo relevant files found for this query.\n";
                }

                let ctx = "--- Relevant Memory (Semantic Search) ---\n";
                for (const item of combined) {
                    // Normalize filename for the AI: remove path and extension
                    // "misc/Research/Foo.pdf" -> "Foo"
                    const rawName = item.chunk.filePath.split('/').pop() || "";
                    const cleanName = rawName.replace(/\.(pdf|md|txt)(\.source\.md)?$/i, "");
                    
                    // Add [Boosted] tag for debug clarity if it was a filename match
                    const tag = item.similarity === 1.0 ? " (Exact Match)" : "";
                    ctx += `\n### Source: ${cleanName}${tag}\n${item.chunk.content}\n---\n`;
                }
                return ctx;
            } catch (e) {
                console.error("[RAG] Search failed", e);
                return await this.getLegacyKnowledgeContext();
            }
        } else {
            return await this.getLegacyKnowledgeContext();
        }
    }

    private async getLegacyKnowledgeContext(): Promise<string> {
        // Get all files in misc/
        const files = await db.files.where('path').startsWith('misc/').toArray();
        const readableFiles = files.filter(f => !f.deleted && f.type === 'file');
        
        let ctx = "--- Knowledge Base (Misc Folder) ---\n";
        if (readableFiles.length === 0) return ctx + "No files found in Knowledge Base.\n";

        let totalLength = 0;
        // Reducing limit to 8k (~2k tokens) to be extremely safe with Groq Free Tier (12k TPM)
        const CHAR_LIMIT = 8000; 


        // 1. Identify Sources to avoid duplication
        const sourcePaths = new Set(readableFiles.map(f => f.path));

        for (const file of readableFiles) {
            if (totalLength > CHAR_LIMIT) {
                ctx += `\n[System] Context limit reached. Some files omitted.\n`;
                break;
            }

            // Check if this is a raw PDF that has a Shadow Source
            const potentialSourcePath = file.path + '.source.md';
            if (file.path.endsWith('.pdf') && sourcePaths.has(potentialSourcePath)) {
                // Skip the raw PDF, we will read the .source.md instead
                continue;
            }

            // Include text-based files and PDFs
            const isText = file.path.endsWith('.md') || file.path.endsWith('.txt');
            const isPdf = file.path.endsWith('.pdf');
            
            if (isText || isPdf) {
                // Ensure content is string before string operations
                if (typeof file.content !== 'string') {
                    // Binary content (e.g. locally stored PDF).
                    // We cannot include binary in AI Context.
                    // However, we likely have a .source.md for this PDF, so we skipped it above (if source exists).
                    // If source does NOT exist (e.g. old file or failed extract), and we have binary, we simply say "Binary Content".
                    ctx += `\nFile: ${file.path} (Binary Content - Use Source)\n---\n`;
                    continue;
                }

                // Truncate individual massive files (e.g. books) to 10k chars (approx 2.5k tokens)
                const content = file.content.length > 10000 
                    ? file.content.substring(0, 10000) + "\n...[Content Truncated]..." 
                    : file.content;
                
                ctx += `\nFile: ${file.path}\nContent:\n${content}\n---\n`;
                totalLength += content.length;
            } else {
                ctx += `\nFile: ${file.path} (Non-text file, content unavailable)\n---\n`;
            }
        }
        return ctx;

    }
}
